{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "\n",
    "This notebook contains some functions that are used frequently throughout this project. They are explained here. Copies of these functions are available in `modules/helper.py` (with the exception of the dataset class) so that they can be imported in the different notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from IPython.display import clear_output\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load model and data\n",
    "model = models.googlenet(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]   \n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    ImageNetSubset(\"data/ImageNet_subset/dev_dataset.csv\", \"data/ImageNet_subset/images/\", transform=preprocess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For the data we use a subset of the ImageNet [1] dataset. It was part of the competition [NIPS 2017: Adversarial Learning Development Set](https://www.kaggle.com/google-brain/nips-2017-adversarial-learning-development-set#categories.csv) [2] on Kaggle and is available [here](http://www.kaggle.com).\n",
    "\n",
    "This class is stored in the file `modules/dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetSubset(Dataset):\n",
    "    '''Imports subset of the ImageNet dataset from the Kaggle competion'''\n",
    "    \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "        csv_file (string)              -- Path to the csv file with metadata like labels and fileId.\n",
    "        root_dir (string)              -- Directory with all the images.\n",
    "        transform (callable, optional) -- Optional transform to be applied on a sample.\n",
    "        '''\n",
    "\n",
    "        self.images_meta = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "               \n",
    "    def __len__(self):\n",
    "        return len(self.images_meta)\n",
    "    \n",
    "    def __getitem__(self, idx):     \n",
    "        image_path = self.root_dir\n",
    "        image_name = self.images_meta[\"ImageId\"][idx]\n",
    "        label = self.images_meta[\"TrueLabel\"][idx]\n",
    "        \n",
    "        ## Load image\n",
    "        image = Image.open(image_path + image_name + \".png\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        ## Format label. Labels in dataset are 1 indexed but 0 indexed in model. Make all 0 indexed.\n",
    "        label = torch.tensor(label-1, dtype=torch.long)\n",
    "        \n",
    "        ## Move data to cuda if available\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_name(idx):\n",
    "    '''\n",
    "    Converts the output class index from the googleNet to the respective name.\n",
    "    \n",
    "    Input:\n",
    "    idx  -- Class index as integer\n",
    "    \n",
    "    Returns:\n",
    "    name -- Class names corresponding to idx as string\n",
    "    '''\n",
    "    \n",
    "    ## Load dictionary from file    \n",
    "    names = pd.read_csv(\"./data/ImageNet_subset/categories.csv\")\n",
    "    \n",
    "    ## Retrieve class name for idx\n",
    "    name = names.iloc[idx][\"CategoryName\"]\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(tensor):\n",
    "    '''\n",
    "    De-normalizes an image as a tensor and converts it back into an 8bit image object.\n",
    "    \n",
    "    Inputs:\n",
    "    tensor -- PyTorch tensor of shape (1, 3, 224, 224)\n",
    "    \n",
    "    Returns:\n",
    "    image  -- De-normalized image object\n",
    "    '''\n",
    "    \n",
    "    ## Detach computation graph and remove batch dimension\n",
    "    tensor = tensor.detach().clone()    \n",
    "    tensor.squeeze_()\n",
    "    \n",
    "    ## De-normalize tensor image\n",
    "    invert_preprocess = transforms.Compose([\n",
    "        transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    ])\n",
    "      \n",
    "    image = invert_preprocess(tensor)      \n",
    "    image = np.array(image.detach())\n",
    "    \n",
    "    ## Rescale to range 0-255 and convert datatype into 8bit\n",
    "    image = image * 255    \n",
    "    image = np.uint8(image)\n",
    "    \n",
    "    ## Swap axes to get the expected shape (224, 224, 3)\n",
    "    image = np.swapaxes(image, 0, 2)\n",
    "    \n",
    "    ## Rotate and flip the image, then convert to image object\n",
    "    image = np.flipud(np.rot90(image))\n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "We use the trained googleNet [3]. It is available through the `Torchvision` library. It expects the data to be 3 channel RGB with a size of at least 224. The data has to be scaled into the range $[0, 1]$ and then centered, see [here](https://pytorch.org/hub/pytorch_vision_googlenet/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image, target_label, return_grad=False):\n",
    "    '''\n",
    "    Predicts the class of the given image and compares the prediction with the provided label.\n",
    "    \n",
    "    Inputs:\n",
    "    model             -- net\n",
    "    image             -- Input image as tensor of shape (1, 3, 224, 224)\n",
    "    target_label      -- Target label as tensor of shape (1)\n",
    "    return_grad       -- Returns gradient if set True\n",
    "    \n",
    "    Returns:\n",
    "    predicted_classes -- Numpy array of top 5 predicted class indices\n",
    "    confidences       -- Numpy array of top 5 confidences in descending order\n",
    "    gradient          -- None if return_grad=False. Otherwise the gradient from the prediction\n",
    "                         as a tensor of shape ().\n",
    "    '''      \n",
    "     \n",
    "    if return_grad == True:\n",
    "        image.requires_grad=True\n",
    "        prediction = model(image)\n",
    "               \n",
    "        # Zero gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate loss using the class index for pandas and get gradient\n",
    "        loss = F.nll_loss(prediction, target_label)\n",
    "        loss.backward()\n",
    "        gradient = image.grad.data\n",
    "        \n",
    "    else:           \n",
    "        gradient = None\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image)  \n",
    "\n",
    "    # Get class index and confidence for prediction \n",
    "    prediction = torch.nn.functional.softmax(prediction[0].cpu().detach(), dim=0).numpy()\n",
    "   \n",
    "    # Get top 5 class indices\n",
    "    predicted_classes = prediction.argsort()[-5:][::-1]\n",
    "        \n",
    "    # Get largest confidences\n",
    "    confidences = prediction[predicted_classes]\n",
    "    \n",
    "    return predicted_classes, confidences, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attack(image_clean, image_adv, conf_clean, conf_adv, label_clean, label_adv, label_target, idx,\n",
    "                    folder=None):\n",
    "    '''\n",
    "    Summarizes attack by printing info and displaying the image along with the adversary and the isolated\n",
    "    perturbance. Saves image to the folder\n",
    "    \n",
    "    Inputs:\n",
    "    image_clean     -- Clean image as tensor of shape (1, 1, 28, 28)\n",
    "    image_adv       -- Adversarial image as tensor of shape (1, 1, 28, 28)\n",
    "    conf_clean      -- Confidence for the clean image\n",
    "    conf_adv        -- Confidence for the adversarial image\n",
    "    label_clean     -- Predicted label from the clean image\n",
    "    label_adv       -- Predicted label from the adversarial image\n",
    "    label_target    -- Target label as tensor of shape (1)\n",
    "    idx             -- Sample index used for filename of plot export\n",
    "    folder          -- If not None folder to which the image is saved.\n",
    "    '''\n",
    "   \n",
    "    ## Get label names from index\n",
    "    name_target = idx_to_name(label_target.detach().numpy()[0])\n",
    "    name_clean = idx_to_name(label_clean)\n",
    "    name_adv = idx_to_name(label_adv)\n",
    "    \n",
    "    ## Isloate perturbance\n",
    "    perturbance = image_adv - image_clean\n",
    "    \n",
    "    ## Text\n",
    "    print(\"\\t\\t\\tClean image\\t Adversarial image\\n\")    \n",
    "    print(\"Actual class: \\t\\t{}\\t\\t\\t{}\".format(name_target, name_target ))\n",
    "    print(\"Predicted class: \\t{}\\t\\t\\t{}\".format(name_clean, name_adv ))\n",
    "    print(\"Confidence: \\t\\t{:.2f}%\\t\\t\\t\\t{:.2f}%\\n\".format(conf_clean*100, conf_adv*100))\n",
    "    \n",
    "    ## Plots\n",
    "    f = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    ax = f.add_subplot(221)\n",
    "    ax2 = f.add_subplot(222)\n",
    "    ax3 = f.add_subplot(223)\n",
    "    \n",
    "    im1 = show_tensor_image(image_clean)\n",
    "    im2 = show_tensor_image(perturbance)\n",
    "    im3 = show_tensor_image(image_adv)\n",
    "    \n",
    "    ax.imshow(im1)\n",
    "    ax.set_title(\"Clean example\", fontsize=25)\n",
    "    ax.axis('off')\n",
    "    ax2.imshow(im2)\n",
    "    ax2.set_title(\"Perturbance\", fontsize=25)\n",
    "    ax2.axis('off')\n",
    "    ax3.imshow(im3)\n",
    "    ax3.set_title(\"Adversarial example\", fontsize=25)\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ## Save figure\n",
    "    if folder is not None:\n",
    "        f.tight_layout()\n",
    "        f.savefig(\"plots/\" + str(folder) + \"/\"+ str(folder) +\"-sample_\" + str(int(idx)) + \"_pair.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
